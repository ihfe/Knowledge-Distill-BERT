ğŸ“Œä¸€ï¼‰æ•°æ®é›†

9ä¸ªæ ‡ç­¾ï¼Œç®—æ˜¯9åˆ†ç±»å•¦~

| æ ‡ç­¾     | å«ä¹‰                                          |
|----------|-----------------------------------------------|
| B-PER    | äººåå¼€å§‹ (Beginning of a person entity)       |
| I-PER    | äººåå†…éƒ¨ (Inside a person entity)             |
| B-LOC    | åœ°åå¼€å§‹                                      |
| I-LOC    | åœ°åå†…éƒ¨                                      |
| B-ORG    | ç»„ç»‡åå¼€å§‹                                    |
| I-ORG    | ç»„ç»‡åå†…éƒ¨                                    |
| B-MISC   | å…¶ä»–å®ä½“å¼€å§‹                                  |
| I-MISC   | å…¶ä»–å®ä½“å†…éƒ¨                                  |
| O        | éå®ä½“ (Outside)                              |



æµ‹è¯•é›†ï¼šå› ä¸ºæ˜¯ç”¨äº**ç¦»çº¿è¯„ä¼°**çš„ï¼Œä¸æ˜¯ç°å®éƒ¨ç½²æµ‹è¯•ã€‚æ‰€ä»¥é‡Œé¢ä¹Ÿæ˜¯æœ‰æ ‡æ³¨çš„ï¼ˆNERæ ‡ç­¾ä¹Ÿç»™å‡ºï¼‰ï¼Œ

ğŸ“ŒäºŒï¼‰
æˆ‘ä»¬å°†æ•°æ®é›†ä¸­çš„æ•°æ®è½¬ä¸º`input_ids`,`attention_mask`,`labels`;
- åœ¨æ­¤ä¹‹å‰ä¸€å®šæ˜¯å·²ç»å®Œæˆäº†label2idçš„æ“ä½œï¼›
- å¯¹äº`labels`ä¸­çš„æ•°ï¼Œè¦ä¹ˆæ˜¯æ ‡ç­¾æ‰€å¯¹åº”çš„idï¼Œè¦ä¹ˆæ˜¯-100(ä¹Ÿå°±æ˜¯å¡«å……çš„å†…å®¹)ï¼›
- å¯¹äºæ¯ä¸ªsentenceçš„`input_ids`,`attention_mask`,`labels`ï¼Œlen()éƒ½æ˜¯max_len

ğŸ“Œä¸‰ï¼‰ç›¸å…³å·¥ä½œ

å°è¯•äº†ä¸¤ç§å­¦ç”Ÿæ¨¡å‹ï¼šå­¦ç”Ÿæ¨¡å‹2å’Œå­¦ç”Ÿæ¨¡å‹3
- â‘ å­¦ç”Ÿæ¨¡å‹1: è‡ªå®šä¹‰6å±‚bertæ¨¡å‹ï¼›ä½¿ç”¨`transformer`ä¸­çš„`BertConfig`å»ä¿®æ”¹`BERT`æ¨¡å‹çš„å±‚æ•°ã€éšè—å±‚ç»´åº¦ç­‰è¶…å‚æ•°ã€ååˆ†ä¸å»ºè®®ã€‘
- â‘¡å­¦ç”Ÿæ¨¡å‹2: å­¦ç”Ÿæ¨¡å‹æˆªå–è€å¸ˆæ¨¡å‹çš„å‰å‡ å±‚
```python
from transformers import BertModel

# åŠ è½½å®Œæ•´çš„é¢„è®­ç»ƒæ¨¡å‹
teacher_model = BertModel.from_pretrained("bert-base-uncased")

# æ‹·è´å‰6å±‚
from transformers import BertConfig, BertModel

# å¤åˆ¶ config å¹¶ä¿®æ”¹å±‚æ•°
config = teacher_model.config
config.num_hidden_layers = 6

# æ–°å»ºå­¦ç”Ÿæ¨¡å‹
student_model = BertModel(config)

# æ‹·è´å‰6å±‚ encoder å‚æ•°
student_model.embeddings.load_state_dict(teacher_model.embeddings.state_dict())
student_model.encoder.layer[:6] = teacher_model.encoder.layer[:6]
```

- â‘¢å­¦ç”Ÿæ¨¡å‹3:æ•™å¸ˆæ¨¡å‹ç”¨å‚æ•°é‡å¤§çš„é¢„è®­ç»ƒæ¨¡å‹å¦‚`Bert-Large`,å­¦ç”Ÿæ¨¡å‹ç”¨å‚æ•°é‡å°çš„é¢„è®­ç»ƒæ¨¡å‹å¦‚`DistilBERT` 

- å†æˆ–è€…åƒæ˜¯`DistilBERT`,å¯ä»¥æ‰‹åŠ¨ä»åŠ è½½å¥½çš„æ•™å¸ˆæ¨¡å‹ä¸­æå–æŸäº›å±‚çš„æƒé‡ï¼Œç„¶åèµ‹å€¼ç»™ä½ è‡ªå®šä¹‰çš„å­¦ç”Ÿæ¨¡å‹ã€‚
```python
from transformers import BertModel, BertConfig

# === 1. åŠ è½½æ•™å¸ˆæ¨¡å‹ï¼ˆ12å±‚ BERTï¼‰ ===
teacher_model = BertModel.from_pretrained("bert-base-uncased")

# === 2. åˆ›å»ºå­¦ç”Ÿæ¨¡å‹é…ç½®ï¼ˆ6å±‚ï¼‰ ===
student_config = copy.deepcopy(teacher_model.config)
student_config.num_hidden_layers = 6
student_model = BertModel(student_config)

# === 3. æ‹·è´ embeddings å±‚ï¼ˆä¸€èˆ¬å…±äº«ï¼‰===
student_model.embeddings.load_state_dict(teacher_model.embeddings.state_dict())

# === 4. é€‰å–æ•™å¸ˆæ¨¡å‹ä¸­çš„å±‚ï¼ˆæ¯éš”ä¸€å±‚ï¼‰æ‹·è´åˆ°å­¦ç”Ÿæ¨¡å‹ ===
selected_teacher_layers = [0, 2, 4, 6, 8, 10]

for student_layer_idx, teacher_layer_idx in enumerate(selected_teacher_layers):
    student_model.encoder.layer[student_layer_idx].load_state_dict(
        teacher_model.encoder.layer[teacher_layer_idx].state_dict()
    )

# === 5. é€‰æ‹©æ€§æ‹·è´ poolerï¼ˆä¸€èˆ¬ç”¨äºå¥å­åˆ†ç±»ä»»åŠ¡ï¼‰===
student_model.pooler.load_state_dict(teacher_model.pooler.state_dict())

print("âœ… å­¦ç”Ÿæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ˆ6 å±‚ BERTï¼‰")

```

ğŸ“Œå››ï¼‰
æ¨¡å‹æ•ˆæœ
- å­¦ç”Ÿæ¨¡å‹çš„æ•ˆæœä¸€èˆ¬ä¸å¦‚æ•™å¸ˆæ¨¡å‹
    - å­¦ç”Ÿæ¨¡å‹æ˜¯ä¸ºäº†æ›´å°ã€æ›´å¿«ã€æ›´é€‚åˆéƒ¨ç½²
- è’¸é¦å¾—åˆ°çš„å°æ¨¡å‹æ•ˆæœè¦æ¯”ç›´æ¥è®­ç»ƒå¾—åˆ°çš„å°æ¨¡å‹æ•ˆæœå¥½ï¼ˆä¸è¿‡æˆ‘ä»…å°è¯•äº†ä¸‰æ¬¡ï¼‰

ğŸ“Œäº”ï¼‰
è’¸é¦ç›¸å…³æ–‡ç« 
- DistilBERTï¼šhttps://arxiv.org/pdf/1910.01108
   - ä½œè€…æŠŠ Bert ä» 12 å±‚å‹ç¼©åˆ° 6 å±‚ï¼Œä»¥ 3% çš„å‡†ç¡®åº¦ä»£ä»·æ¢æ¥ 40% çš„å‚æ•°å‹ç¼©å’Œ 60% çš„é¢„æµ‹æé€Ÿã€‚
- BiLSTMï¼šhttps://arxiv.org/pdf/1903.12136

Distilled BiLSTMå°†BERTæ¨¡å‹å½“ä½œTeacheræ¨¡å‹ï¼Œå¯¹BERTè¿›è¡Œè’¸é¦ï¼Œä½¿å¾—è’¸é¦å¾—åˆ°çš„Studentæ¨¡å‹BiLSTMæ¨¡å‹ä¸ELMoæ¨¡å‹å…·æœ‰ç›¸åŒçš„æ•ˆæœï¼Œä½†æ˜¯å‚æ•°é‡å´å‡å°äº†100å€ï¼ŒåŒæ—¶ï¼Œè®¡ç®—æ—¶é—´ç¼©çŸ­äº†15å€ã€‚
- è§£å†³NLPä¸­ä¸¤ä¸ªä»»åŠ¡ï¼šå•ä¸ªå¥å­çš„åˆ†ç±»ï¼Œå¥å­å¯¹ä»»åŠ¡
- æå‡ºäº†æ•°æ®å¢å¼ºçš„æ–¹æ³•ã€çœ‹ä¸‹å›¾ã€‘
    - ![æ•°æ®å¢å¼º](./æ•°æ®å¢å¼º.jpg)

